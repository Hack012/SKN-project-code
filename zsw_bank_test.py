import os
import streamlit as st
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain_chroma import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import PyPDFLoader


# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY = "[API í‚¤ ì…ë ¥]"
#DATA_PATH = "./data_kb"
DATA_PATH = "./data"
CHROMA_PATH = "./chroma_db"

# def load_documents():
#     """PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° DBì— ì €ì¥"""
#     documents = []
#     for file in os.listdir(DATA_PATH):
#         if file.endswith(".pdf"):
#             print(f"ğŸ“„ PDF ë¡œë“œ ì¤‘: {file}")
#             loader = PyPDFLoader(os.path.join(DATA_PATH, file))
#             docs = loader.load()
#             print(f"ğŸ”¹ {file}ì—ì„œ {len(docs)}ê°œì˜ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
#             documents.extend(loader.load())
#     return documents

def load_documents():
    """í•˜ìœ„ í´ë”ê¹Œì§€ í¬í•¨í•˜ì—¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ë²¡í„° DBì— ì €ì¥"""
    documents = []
    for root, _, files in os.walk(DATA_PATH):
        for file in files:
            if file.endswith('.pdf'):
                pdf_path = os.path.join(root, file)
                print(f"ğŸ“„ PDF ë¡œë“œ ì¤‘: {pdf_path}")

                loader = PyPDFLoader(pdf_path)
                docs = loader.load()

                print(f"ğŸ”¹ {file}ì—ì„œ {len(docs)}ê°œì˜ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
                documents.extend(docs)
    
    return documents

def create_chroma_db():
    """ChromaDB ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë¬¸ì„œë¥¼ ì €ì¥"""
    documents = load_documents()
    print(f"ğŸ“š ì´ {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.split_documents(documents)
    print(f"ğŸ” ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: ì´ {len(docs)}ê°œì˜ ì²­í¬ ìƒì„±ë¨")
    
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) # text-embedding-ada-002
    db = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_PATH)
    print("âœ… ChromaDB ì €ì¥ ì™„ë£Œ!")
    return db

def get_qa_chain_with_memory(db):
    """ê³¼ê±° ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” QA ì²´ì¸ ìƒì„±"""
    retriever = db.as_retriever(search_kwargs={"k": 10})
    llm = ChatOpenAI(model_name="gpt-4o", openai_api_key=OPENAI_API_KEY, temperature=0.5)
    
    # ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ëŠ” ë©”ëª¨ë¦¬ ì„¤ì •
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm, 
        retriever=retriever, 
        chain_type="stuff",
        memory=memory
    )

    # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì¶œë ¥í•˜ëŠ” ì»¤ìŠ¤í…€ ì‹¤í–‰ í•¨ìˆ˜
    def custom_run(query):
        retrieved_docs = retriever.get_relevant_documents(query)
        print(f"\nğŸ” ì§ˆë¬¸: {query}")
        print(f"ğŸ“‚ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(retrieved_docs)}")

        # ì€í–‰ë³„ë¡œ ëŒ€ì¶œ ìƒí’ˆ ì •ë¦¬
        bank_products = {}
        sources = set()

        for doc in retrieved_docs: 
            bank_name = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ").split(os.sep)[-2]
            sources.add(doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"))

            if bank_name not in bank_products:
                bank_products[bank_name] = []

            bank_products[bank_name].append(doc.page_content[:700]) # ìµœëŒ€  700ì ê¹Œì§€ ì €ì¥

        # ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        bank_info_text = "**ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´:**\n"
        for bank, products in bank_products.items():
            bank_info_text += f"\nğŸ¦ **{bank.upper()}**\n"
            for i, product in enumerate(products, start=1):
                bank_info_text += f"{i}. {product}...\n"

        # QA Chain ì‹¤í–‰ (ì€í–‰ë³„ ì •ë³´ í¬í•¨)
        modified_query = f"{query}\n\n{bank_info_text}"
        print(modified_query)
        response = qa_chain.run(modified_query)

        # ìµœì¢… ì‘ë‹µ ì •ë¦¬
        response_text = f"ğŸ’¡ **AI ë‹µë³€:**\n{response}\n\nğŸ“Œ **ì¶œì²˜:** {', '.join(sources)}"
        return response_text

        # # ì¶œì²˜ (ì°¸ê³ í•œ PDF íŒŒì¼ ë¦¬ìŠ¤íŠ¸)
        # sources = list(set(doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ") for doc in retrieved_docs))
        
        # for i, doc in enumerate(retrieved_docs):
        #     print(f"ğŸ“‘ ë¬¸ì„œ {i+1}: {doc.page_content[:200]}... (ì¶œì²˜: {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')})")

        # # QA ì‹¤í–‰
        # response = qa_chain.run(query)

        # # ë‹µë³€ì´ ë¬¸ìì—´ì´ë¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ë”•ì…”ë„ˆë¦¬ë¼ë©´ "answer" í‚¤ë¡œë¶€í„° ê°’ ì¶”ì¶œ
        # if isinstance(response, str):
        #     response_text = response
        # else:
        #     response_text = response.get("answer", "ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # response_text += f"\n\nğŸ“Œ **ì¶œì²˜:** {', '.join(sources)}"  # ì¶œì²˜ ì •ë³´ ì¶”ê°€
        # return response_text

    return custom_run

def main():
    st.title("ğŸ’¬ì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ Q&A ì±—ë´‡")
    st.write("ì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")

    # ChromaDB ì´ˆê¸°í™”
    if not os.path.exists(CHROMA_PATH):
        st.info("ë¬¸ì„œ DBë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
        db = create_chroma_db()
    else:
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)

    qa_chain = get_qa_chain_with_memory(db)

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    
    if st.button("ì§ˆë¬¸í•˜ê¸°") and user_input:
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = qa_chain(user_input)  # ê³¼ê±° ëŒ€í™” ë°˜ì˜ë¨
            st.success("ğŸ“ ë‹µë³€:")
            st.write(response)  # PDF ì¶œì²˜ í¬í•¨

            # ì‚¬ìš©ì ì§ˆë¬¸ ë° ë‹µë³€ ì €ì¥
            if "history" not in st.session_state:
                st.session_state.history = []
            st.session_state.history.append((user_input, response))

    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    if "history" in st.session_state and st.session_state.history:
        st.write("### ğŸ“œ ì´ì „ ëŒ€í™” ê¸°ë¡")
        for question, answer in st.session_state.history:
            st.write(f"**Q:** {question}")
            st.write(f"**A:** {answer}")
            st.write("---")

if __name__ == "__main__":
    main()
